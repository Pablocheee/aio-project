export default async function handler(req, res) {
    // –†–∞–∑—Ä–µ—à–∞–µ–º —Ç–æ–ª—å–∫–æ POST –∑–∞–ø—Ä–æ—Å—ã
    if (req.method !== 'POST') {
        return res.status(405).json({ error: 'Method Not Allowed' });
    }

    try {
        const { message, history = [], isFinal, clientData } = req.body;

        // 1. –ü–†–û–í–ï–†–ö–ê –ö–õ–Æ–ß–ï–ô
        const GROQ_KEY = process.env.GROQ_API_KEY;
        const TG_TOKEN = process.env.TG_TOKEN;
        const TG_CHAT_ID = process.env.TG_CHAT_ID;

        // 2. –§–ò–ù–ê–õ–¨–ù–´–ô –®–ê–ì: –û–¢–ü–†–ê–í–ö–ê –í TELEGRAM
        if (isFinal && clientData) {
            const orderId = Math.floor(100000 + Math.random() * 900000);
            const report = `
üöÄ **NEW AI CONTRACT #${orderId}**
üåê **URL:** ${clientData.url}
üì± **Contact:** ${clientData.contact}
‚è≥ **Status:** Ready for analysis
            `;

            await fetch(`https://api.telegram.org/bot${TG_TOKEN}/sendMessage`, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    chat_id: TG_CHAT_ID,
                    text: report,
                    parse_mode: "Markdown"
                })
            });

            return res.status(200).json({ reply: "Finalized", orderId });
        }

        // 3. –ó–ê–ü–†–û–° –ö –ò–ò (GROQ + LLAMA 3)
        const response = await fetch('https://api.groq.com/openai/v1/chat/completions', {
            method: 'POST',
            headers: {
                'Authorization': `Bearer ${GROQ_KEY}`,
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({
                model: "llama-3.3-70b-versatile",
                messages: [
                    { 
                        role: "system", 
                        content: `–¢—ã ‚Äî –ò–ò-—Å–æ—Ç—Ä—É–¥–Ω–∏–∫ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–π –∫–æ–º–ø–∞–Ω–∏–∏ AIO.CORE. 
                        –¢–í–û–ô –°–¢–ò–õ–¨: –õ–∞–∫–æ–Ω–∏—á–Ω—ã–π, —Ö–æ–ª–æ–¥–Ω—ã–π, –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π. –ù–∏–∫–∞–∫–∏—Ö –ª–∏—à–Ω–∏—Ö —Å–ª–æ–≤ –∏ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–π.
                        –¢–í–û–Ø –ó–ê–î–ê–ß–ê: –°–æ–±—Ä–∞—Ç—å —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è URL –ø—Ä–æ–µ–∫—Ç–∞ –∏ –µ–≥–æ –∫–æ–Ω—Ç–∞–∫—Ç (TG/Email).
                        –ò–ù–°–¢–†–£–ö–¶–ò–Ø: 
                        - –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∏—á–µ–≥–æ –Ω–µ –ø—Ä–∏—Å–ª–∞–ª, –∑–∞–ø—Ä–æ—Å–∏ URL. 
                        - –ï—Å–ª–∏ –µ—Å—Ç—å URL, –Ω–æ –Ω–µ—Ç –∫–æ–Ω—Ç–∞–∫—Ç–∞ ‚Äî –∑–∞–ø—Ä–æ—Å–∏ –∫–æ–Ω—Ç–∞–∫—Ç.
                        - –ü–∏—à–∏ –Ω–µ –±–æ–ª–µ–µ 1-2 –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.
                        - –ö–∞–∫ —Ç–æ–ª—å–∫–æ –ø–æ–ª—É—á–∏–ª –û–ë–ê –∑–Ω–∞—á–µ–Ω–∏—è, –Ω–∞–ø–∏—à–∏ —Å—Ç—Ä–æ–≥–æ: "–î–∞–Ω–Ω—ã–µ –ø—Ä–∏–Ω—è—Ç—ã. –ü–ê–ö–ï–¢ –°–§–û–†–ú–ò–†–û–í–ê–ù."` 
                    },
                    // –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç OpenAI
                    ...history.map(h => ({
                        role: h.role === 'model' ? 'assistant' : 'user',
                        content: Array.isArray(h.parts) ? h.parts[0].text : h.content
                    })),
                    { role: "user", content: message || "–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è" }
                ],
                temperature: 0.5, // –î–µ–ª–∞–µ–º –µ–≥–æ –±–æ–ª–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º—ã–º
                max_tokens: 150
            })
        });

        const data = await response.json();

        if (data.error) {
            console.error("GROQ_API_ERROR:", data.error);
            return res.status(500).json({ error: data.error.message });
        }

        const aiReply = data.choices[0].message.content;
        res.status(200).json({ reply: aiReply });

    } catch (e) {
        console.error("SERVER_ERROR:", e);
        res.status(500).json({ error: "Internal Server Error", details: e.message });
    }
}
